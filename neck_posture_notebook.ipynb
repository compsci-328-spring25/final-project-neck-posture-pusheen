{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this documents, we'll check if all the library has been correctly installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS START --\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import datetime\n",
    "import pathlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy import signal\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "# -- IMPORTS END --\n",
    "\n",
    "# enable zooming into graphs\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [9, 6] # width, height in inches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xyz(data):\n",
    "\n",
    "    # Set axis\n",
    "    axis = ['x', 'y', 'z']\n",
    "\n",
    "    # Generate datetime index\n",
    "    start = pd.Timestamp('2023-01-01')\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=1)\n",
    "\n",
    "    for i in range(len(axis)):\n",
    "\n",
    "        # Select random window\n",
    "        start = 0\n",
    "        end = 10 * 100\n",
    "        window = data.iloc[start:end]\n",
    "\n",
    "        ax = axs.flat[i]\n",
    "\n",
    "        # Plot data\n",
    "        ax.set_xticklabels([])        \n",
    "        ax.plot(window.index, window[axis[i]], label=axis[i])\n",
    "\n",
    "        # Plot peaks\n",
    "        # peak_mask = window['peaks'] != 0\n",
    "        # ax.plot(window.index[peak_mask], window['accel_mag'][peak_mask], 'ro', label='Peaks')\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_title(f\"Axis-{axis[i]}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize model\n",
    "def viz_tree(dt_model,features_frames,cnames):\n",
    "    # Fix feature names as list\n",
    "    feature_names = features_frames.columns.tolist()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,4))\n",
    "    tree.plot_tree(dt_model,\n",
    "                   feature_names=feature_names,\n",
    "                   fontsize=7,\n",
    "                   class_names=cnames,\n",
    "                   filled=True,\n",
    "                   ax=ax)\n",
    "\n",
    "    plt.title('Decision Tree')\n",
    "    plt.savefig('dt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude\n",
    "    data['accel_mag'] = np.sqrt(data['accelerationX']**2 + data['accelerationY']**2 + data['accelerationZ']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 5 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(window):\n",
    "    features = {}\n",
    "    features['avg'] = window['filtered_accel_mag'].mean()\n",
    "    features['max'] = window['filtered_accel_mag'].quantile(1)\n",
    "    features['med'] = window['filtered_accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['filtered_accel_mag'].quantile(0)\n",
    "    features['q25'] = window['filtered_accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['filtered_accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['filtered_accel_mag'].std()\n",
    "    df = pd.DataFrame()\n",
    "    df = df._append(features,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns\n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['activity']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract windows and features\n",
    "def extract_features(data, window_sec, sample_rate, activity):\n",
    "\twindow_str = f\"{window_sec}s\"\n",
    "\tdata['time'] = pd.to_datetime(data['time'])\n",
    "\tdata.set_index('time', inplace=True)\n",
    "\tresampled_data = data.resample(window_str)\n",
    "\tall_features = []\n",
    "\tfor time, window in resampled_data:\n",
    "\t\tfeatures = add_features(window)\n",
    "\t\tnew_row = {\n",
    "\t\t\t'avg': features.iloc[0]['avg'],\n",
    "\t\t\t'max': features.iloc[0]['max'],\n",
    "\t\t\t'med': features.iloc[0]['med'],\n",
    "\t\t\t'min': features.iloc[0]['min'],\n",
    "\t\t\t'q25': features.iloc[0]['q25'],\n",
    "\t\t\t'q75': features.iloc[0]['q75'],\n",
    "\t\t\t'std': features.iloc[0]['std'],\n",
    "\t\t\t'activity': activity #?\n",
    "\t\t}\n",
    "\t\tall_features.append(new_row)\n",
    "\treturn pd.DataFrame(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_to_combined_csv(root, output_filename = 'all_data.csv'):\n",
    "    all_data = []\n",
    "    sampling_rate = 100\n",
    "    window_sec = 5\n",
    "\n",
    "    \n",
    "    activity_folders = os.listdir(root)\n",
    "    print(activity_folders)\n",
    "    for folder in activity_folders:\n",
    "        activity_files = glob.glob(f\"{root}/{folder}/*.csv\")\n",
    "\n",
    "        for file in activity_files:\n",
    "            df = pd.read_csv(file, parse_dates=['time'])\n",
    "            df = calc_magnitude(df)\n",
    "            df = remove_noise(df, sampling_rate)\n",
    "            df_features = extract_features(df, window_sec, sampling_rate, folder)\n",
    "            \n",
    "            for index, row in df_features.iterrows():\n",
    "                new_row = {\n",
    "                    'avg': row['avg'],\n",
    "                    'max': row['max'],\n",
    "                    'med': row['med'],\n",
    "                    'min': row['min'],\n",
    "                    'q25': row['q25'],\n",
    "                    'q75': row['q75'],\n",
    "                    'std': row['std'],\n",
    "                    'activity': row['activity']\n",
    "                }\n",
    "                all_data.append(new_row)\n",
    "\n",
    "    print(all_data)\n",
    "    all_data = pd.DataFrame(all_data)\n",
    "    all_data.to_csv(f\"{root}/{output_filename}\")  \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Collect Training Data Into A Combined CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type 'dateutil' not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m             df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]), unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdateutil\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m             df\u001b[38;5;241m.\u001b[39mto_csv(filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtransform_time_to_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/training_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m all_data_to_combined_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/training_data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mtransform_time_to_datetime\u001b[0;34m(root)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print(filename)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdateutil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/cs328/lib/python3.10/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/cs328/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/cs328/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/cs328/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/cs328/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:231\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    225\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got the class instead. Try instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 231\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, NumpyEADtype):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# Ensure we don't end up with a NumpyExtensionArray\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/cs328/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1645\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;66;03m# GH#51523 - Series.astype(np.integer) doesn't show\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m         \u001b[38;5;66;03m# numpy deprecation warning of np.integer\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m         \u001b[38;5;66;03m# Hence enabling DeprecationWarning\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m-> 1645\u001b[0m         npdtype \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;66;03m# np.dtype uses `eval` which can raise SyntaxError\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type 'dateutil' not understood"
     ]
    }
   ],
   "source": [
    "def transform_time_to_datetime(root):\n",
    "    \n",
    "    dateparse = lambda dates: [pd.to_datetime(d, unit='ns') for d in dates]\n",
    "    # Get list of all activity folders\n",
    "    activity_folders = os.listdir(root)\n",
    "    # print(activity_folders)\n",
    "\n",
    "    for folder in activity_folders:\n",
    "        # print(folder)\n",
    "        files = glob.glob(f\"{root}/{folder}/*.csv\")\n",
    "        for filename in files:\n",
    "            # print(filename)\n",
    "            df = pd.read_csv(filename, parse_dates=['time'])\n",
    "            df['time'] = pd.to_datetime(pd.to_numeric(df['time']), unit='ns')\n",
    "            df.to_csv(filename, index=False)\n",
    "\n",
    "transform_time_to_datetime('data/training_data')\n",
    "\n",
    "all_data_to_combined_csv('data/training_data', 'all_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs328",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
