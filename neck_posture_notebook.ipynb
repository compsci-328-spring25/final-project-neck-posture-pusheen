{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this documents, we'll check if all the library has been correctly installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS START --\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import datetime\n",
    "import pathlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy import signal\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "# -- IMPORTS END --\n",
    "\n",
    "# enable zooming into graphs\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [9, 6] # width, height in inches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xyz(data):\n",
    "\n",
    "    # Set axis\n",
    "    axis = ['x', 'y', 'z']\n",
    "\n",
    "    # Generate datetime index\n",
    "    start = pd.Timestamp('2023-01-01')\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=1)\n",
    "\n",
    "    for i in range(len(axis)):\n",
    "\n",
    "        # Select random window\n",
    "        start = 0\n",
    "        end = 10 * 100\n",
    "        window = data.iloc[start:end]\n",
    "\n",
    "        ax = axs.flat[i]\n",
    "\n",
    "        # Plot data\n",
    "        ax.set_xticklabels([])        \n",
    "        ax.plot(window.index, window[axis[i]], label=axis[i])\n",
    "\n",
    "        # Plot peaks\n",
    "        # peak_mask = window['peaks'] != 0\n",
    "        # ax.plot(window.index[peak_mask], window['accel_mag'][peak_mask], 'ro', label='Peaks')\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_title(f\"Axis-{axis[i]}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize model\n",
    "def viz_tree(dt_model,features_frames,cnames):\n",
    "    # Fix feature names as list\n",
    "    feature_names = features_frames.columns.tolist()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,4))\n",
    "    tree.plot_tree(dt_model,\n",
    "                   feature_names=feature_names,\n",
    "                   fontsize=7,\n",
    "                   class_names=cnames,\n",
    "                   filled=True,\n",
    "                   ax=ax)\n",
    "\n",
    "    plt.title('Decision Tree')\n",
    "    plt.savefig('dt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude\n",
    "    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 5 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(window):\n",
    "    features = {}\n",
    "    features['avg'] = window['filtered_accel_mag'].mean()\n",
    "    features['max'] = window['filtered_accel_mag'].quantile(1)\n",
    "    features['med'] = window['filtered_accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['filtered_accel_mag'].quantile(0)\n",
    "    features['q25'] = window['filtered_accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['filtered_accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['filtered_accel_mag'].std()\n",
    "    df = pd.DataFrame()\n",
    "    df = df._append(features,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns\n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['activity']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract windows and features\n",
    "def extract_features(data, window_sec, sample_rate, activity):\n",
    "\twindow_str = f\"{window_sec}s\"\n",
    "\tdata['time'] = pd.to_datetime(data['time'])\n",
    "\tdata.set_index('time', inplace=True)\n",
    "\tresampled_data = data.resample(window_str)\n",
    "\tall_features = []\n",
    "\tfor time, window in resampled_data:\n",
    "\t\tfeatures = add_features(window)\n",
    "\t\tnew_row = {\n",
    "\t\t\t'avg': features.iloc[0]['avg'],\n",
    "\t\t\t'max': features.iloc[0]['max'],\n",
    "\t\t\t'med': features.iloc[0]['med'],\n",
    "\t\t\t'min': features.iloc[0]['min'],\n",
    "\t\t\t'q25': features.iloc[0]['q25'],\n",
    "\t\t\t'q75': features.iloc[0]['q75'],\n",
    "\t\t\t'std': features.iloc[0]['std'],\n",
    "\t\t\t'activity': activity #?\n",
    "\t\t}\n",
    "\t\tall_features.append(new_row)\n",
    "\treturn pd.DataFrame(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_to_combined_csv(root, output_filename = 'all_data.csv'):\n",
    "    all_data = []\n",
    "    sampling_rate = 100\n",
    "    window_sec = 5\n",
    "\n",
    "    \n",
    "    activity_folders = os.listdir(root)\n",
    "    print(activity_folders)\n",
    "    for folder in activity_folders:\n",
    "        activity_files = glob.glob(f\"{root}/{folder}/*.csv\")\n",
    "\n",
    "        for file in activity_files:\n",
    "            df = pd.read_csv(file, parse_dates=['time'])\n",
    "            df = calc_magnitude(df)\n",
    "            df = remove_noise(df, sampling_rate)\n",
    "            df_features = extract_features(df, window_sec, sampling_rate, folder)\n",
    "            \n",
    "            for index, row in df_features.iterrows():\n",
    "                new_row = {\n",
    "                    'avg': row['avg'],\n",
    "                    'max': row['max'],\n",
    "                    'med': row['med'],\n",
    "                    'min': row['min'],\n",
    "                    'q25': row['q25'],\n",
    "                    'q75': row['q75'],\n",
    "                    'std': row['std'],\n",
    "                    'activity': row['activity']\n",
    "                }\n",
    "                all_data.append(new_row)\n",
    "\n",
    "    print(all_data)\n",
    "    all_data = pd.DataFrame(all_data)\n",
    "    all_data.to_csv(f\"{root}/{output_filename}\")  \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Collect Training Data Into A Combined CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs328",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
